# Production-Ready Figma Extraction Pipeline

> **The middleware layer that transforms raw Figma API data into Design Intelligence gold**

## üèóÔ∏è Pipeline Architecture Overview

```
Raw Figma Data ‚Üí Normalized Structure ‚Üí Semantic Intelligence ‚Üí Code-Ready Context
      ‚Üì                    ‚Üì                      ‚Üì                    ‚Üì
  [Collection]      [Normalization]        [Inference]         [Enrichment]
```

## üéØ Production Pipeline Strategy

### Modular, Idempotent, Resumable Extraction

The pipeline is designed for **production resilience**:
- **Modular**: Each phase can run independently
- **Idempotent**: Safe to re-run without side effects  
- **Resumable**: Can continue from failure points
- **Partitioned**: Large frames split into manageable modules
- **Cached**: Intelligent caching to handle Figma rate limits

### Frame Selection & Partitioning

```typescript
interface FrameSelectionStrategy {
  // Auto-detection
  detectDevReadyFrames(fileId: string): Promise<string[]>;
  
  // Tag-based selection
  findTaggedFrames(fileId: string, tags: string[]): Promise<string[]>; // #for-dev, #dev-ready
  
  // Size-based partitioning
  partitionLargeFrame(nodeId: string): Promise<FramePartition[]>;
}

interface FramePartition {
  id: string;
  type: 'header' | 'content' | 'footer' | 'sidebar' | 'modal';
  bounds: Bounds;
  children: string[];
}
```

## Phase 1: Raw Data Collection with Rate Limiting

### Figma MCP Integration Points with Compression

```typescript
interface ProductionFigmaDataCollector {
  // Core node structure with batching
  async collectNodeTree(fileId: string, nodeId: string, opts: CollectionOptions): Promise<FigmaNodeTree>;
  
  // Component definitions with caching
  async collectComponents(fileId: string): Promise<FigmaComponent[]>;
  
  // Design tokens with normalization
  async collectStyles(fileId: string): Promise<FigmaStyle[]>;
  
  // Prototype interactions (lightweight)
  async collectInteractions(fileId: string): Promise<FigmaInteraction[]>;
  
  // Auto-layout with compression
  async collectLayoutData(nodeId: string): Promise<FigmaLayoutData>;
  
  // NEW: Low-res screenshots for visual grounding
  async collectScreenshots(nodeId: string, resolution: 'low' | 'high'): Promise<Screenshot[]>;
}

interface CollectionOptions {
  useCache: boolean;
  compression: 'none' | 'basic' | 'aggressive';
  batchSize: number;
  rateLimit: RateLimitConfig;
}
```

### Smart Data Collection Strategy

```typescript
class ProductionFigmaMCPExtractor {
  private rateLimiter = new RateLimiter({ requests: 100, window: '1m' });
  private cache = new ExtractionCache({ ttl: '24h' });

  async extractRawData(figmaFileId: string, nodeId: string, opts: ExtractionOptions): Promise<RawFigmaData> {
    // Check cache first
    const cacheKey = `${figmaFileId}:${nodeId}:${opts.version}`;
    const cached = await this.cache.get(cacheKey);
    if (cached && opts.useCache) {
      return { ...cached, metadata: { ...cached.metadata, fromCache: true } };
    }

    // Rate limit check
    await this.rateLimiter.acquire();

    // Parallel collection with error handling
    const [
      nodeTree,
      components,
      styles,
      interactions,
      layoutData,
      screenshots
    ] = await Promise.allSettled([
      this.mcpClient.getNodes(figmaFileId, nodeId),
      this.mcpClient.getFileComponents(figmaFileId),
      this.mcpClient.getFileStyles(figmaFileId),
      this.mcpClient.getPrototypeInteractions(figmaFileId),
      this.mcpClient.getNodeLayoutData(nodeId),
      this.mcpClient.getScreenshot(nodeId, { resolution: 'low', maxSize: 150 }) // ‚â§150KB
    ]);

    const rawData = {
      nodeTree: this.handleResult(nodeTree),
      components: this.handleResult(components, []),
      styles: this.handleResult(styles, []),
      interactions: this.handleResult(interactions, []),
      layoutData: this.handleResult(layoutData),
      screenshots: this.handleResult(screenshots, []),
      metadata: {
        extractedAt: new Date().toISOString(),
        fileId: figmaFileId,
        nodeId,
        apiVersion: 'v1',
        fromCache: false,
        compressionLevel: opts.compression
      }
    };

    // Cache successful extraction
    await this.cache.set(cacheKey, rawData);
    
    return rawData;
  }

  private handleResult<T>(result: PromiseSettledResult<T>, fallback?: T): T {
    if (result.status === 'fulfilled') {
      return result.value;
    }
    console.warn('Figma API call failed:', result.reason);
    return fallback as T;
  }
}
```

## Phase 2: Structural Normalization

### Auto-Layout Normalization

```typescript
interface LayoutNormalizer {
  normalizeAutoLayout(rawLayout: FigmaAutoLayout): NormalizedLayout {
    return {
      direction: this.mapDirection(rawLayout.layoutMode),
      mainAxisAlignment: this.mapAlignment(rawLayout.primaryAxisAlignItems),
      crossAxisAlignment: this.mapAlignment(rawLayout.counterAxisAlignItems),
      spacing: this.normalizeSpacing(rawLayout.itemSpacing),
      padding: this.normalizePadding(rawLayout.paddingLeft, rawLayout.paddingTop, /* ... */),
      constraints: this.normalizeConstraints(rawLayout.constraints)
    };
  }

  private mapDirection(layoutMode: string): 'horizontal' | 'vertical' | 'grid' {
    switch (layoutMode) {
      case 'HORIZONTAL': return 'horizontal';
      case 'VERTICAL': return 'vertical';
      default: return 'grid';
    }
  }
}
```

### Text Content Normalization

```typescript
interface TextNormalizer {
  normalizeTextContent(figmaText: FigmaText): NormalizedTextContent {
    return {
      content: figmaText.characters,
      style: {
        family: figmaText.style.fontFamily,
        size: figmaText.style.fontSize,
        weight: this.mapFontWeight(figmaText.style.fontWeight),
        lineHeight: figmaText.style.lineHeightPx
      },
      semantics: {
        isHeading: this.inferHeadingLevel(figmaText),
        isInteractive: this.inferInteractivity(figmaText),
        importance: this.inferImportance(figmaText)
      }
    };
  }
}
```

### Component Instance Mapping

```typescript
interface ComponentMapper {
  mapComponentInstances(rawData: RawFigmaData): ComponentInstanceMap {
    const instances = new Map<string, ComponentInstance>();
    
    rawData.nodeTree.children.forEach(node => {
      if (node.type === 'INSTANCE') {
        const masterComponent = rawData.components.find(c => c.id === node.componentId);
        instances.set(node.id, {
          instanceId: node.id,
          masterId: node.componentId,
          overrides: this.extractOverrides(node, masterComponent),
          variant: this.detectVariant(node, masterComponent)
        });
      }
    });
    
    return instances;
  }
}
```

## Phase 3: Semantic Inference Engine

### Component Role Classification

```typescript
class ComponentRoleClassifier {
  private patterns = {
    button: {
      keywords: ['button', 'btn', 'cta', 'submit', 'action'],
      styles: ['cursor: pointer', 'background-color', 'border-radius'],
      structure: { hasText: true, clickable: true }
    },
    input: {
      keywords: ['input', 'field', 'text', 'email', 'password'],
      styles: ['border', 'background: white', 'padding'],
      structure: { editable: true, hasLabel: true }
    },
    navigation: {
      keywords: ['nav', 'menu', 'link', 'breadcrumb'],
      styles: ['display: flex', 'list-style: none'],
      structure: { hasChildren: true, horizontal: true }
    }
  };

  classifyComponent(normalizedData: NormalizedComponent): ComponentRole {
    const scores = Object.entries(this.patterns).map(([role, pattern]) => ({
      role: role as ComponentRole,
      score: this.calculateScore(normalizedData, pattern)
    }));

    return scores.reduce((best, current) => 
      current.score > best.score ? current : best
    ).role;
  }

  private calculateScore(component: NormalizedComponent, pattern: any): number {
    let score = 0;
    
    // Keyword matching in name
    const nameScore = pattern.keywords.some(keyword => 
      component.name.toLowerCase().includes(keyword)
    ) ? 0.4 : 0;
    
    // Style pattern matching
    const styleScore = this.matchStylePatterns(component.styles, pattern.styles) * 0.3;
    
    // Structural pattern matching
    const structureScore = this.matchStructuralPatterns(component.structure, pattern.structure) * 0.3;
    
    return nameScore + styleScore + structureScore;
  }
}
```

### Intent Inference System

```typescript
class IntentInferenceEngine {
  inferIntent(component: NormalizedComponent, context: PageContext): ComponentIntent {
    const role = this.roleClassifier.classifyComponent(component);
    const priority = this.calculatePriority(component, context);
    const userAction = this.inferUserAction(component, role);
    
    return {
      role,
      priority,
      purpose: this.generatePurpose(component, role, context),
      userAction,
      confidence: this.calculateConfidence([role, priority, userAction])
    };
  }

  private calculatePriority(component: NormalizedComponent, context: PageContext): Priority {
    let priorityScore = 0;
    
    // Visual prominence
    priorityScore += this.calculateVisualWeight(component) * 0.4;
    
    // Position importance
    priorityScore += this.calculatePositionWeight(component) * 0.3;
    
    // Context relevance
    priorityScore += this.calculateContextRelevance(component, context) * 0.3;
    
    if (priorityScore > 0.8) return 'critical';
    if (priorityScore > 0.6) return 'high';
    if (priorityScore > 0.4) return 'medium';
    return 'low';
  }

  private inferUserAction(component: NormalizedComponent, role: ComponentRole): UserAction | undefined {
    const actionMap: Record<ComponentRole, UserAction | undefined> = {
      'primary_cta': 'click',
      'secondary_cta': 'click',
      'navigation': 'navigate',
      'data_input': 'input',
      'data_display': undefined,
      'feedback': undefined,
      'decoration': undefined,
      'structure': undefined,
      'content': undefined
    };
    
    return actionMap[role];
  }
}
```

### Behavioral Pattern Recognition

```typescript
class BehaviorAnalyzer {
  analyzeBehaviors(component: NormalizedComponent, interactions: FigmaInteraction[]): ComponentBehavior[] {
    const behaviors: ComponentBehavior[] = [];
    
    // Direct prototype interactions
    const directInteractions = interactions.filter(i => i.trigger.nodeId === component.id);
    directInteractions.forEach(interaction => {
      behaviors.push(this.mapInteractionToBehavior(interaction));
    });
    
    // Inferred behaviors from component type
    const inferredBehaviors = this.inferBehaviorsFromType(component);
    behaviors.push(...inferredBehaviors);
    
    return behaviors;
  }

  private mapInteractionToBehavior(interaction: FigmaInteraction): ComponentBehavior {
    return {
      trigger: this.mapTriggerType(interaction.trigger.type),
      action: this.mapActionType(interaction.action.type),
      target: interaction.action.destinationId,
      payload: interaction.action.payload
    };
  }

  private inferBehaviorsFromType(component: NormalizedComponent): ComponentBehavior[] {
    const behaviorMap: Record<ComponentRole, ComponentBehavior[]> = {
      'primary_cta': [
        { trigger: 'onClick', action: 'submit', target: 'form' },
        { trigger: 'onClick', action: 'navigate', target: 'next_page' }
      ],
      'data_input': [
        { trigger: 'onFocus', action: 'validate', target: 'field' },
        { trigger: 'onSubmit', action: 'validate', target: 'form' }
      ],
      // ... other mappings
    };
    
    return behaviorMap[component.intent.role] || [];
  }
}
```

## Phase 4: Context Enrichment & Design System Matching

### Production Design System Cross-Reference

```typescript
class DesignSystemMatcher {
  private dsRegistry: DesignSystemRegistry;
  private vectorDB: VectorDatabase;

  constructor() {
    this.dsRegistry = new DesignSystemRegistry();
    this.vectorDB = new VectorDatabase(); // For semantic similarity
  }

  async matchToDesignSystem(
    component: NormalizedComponent,
    projectContext: ProjectContext
  ): Promise<DesignSystemMatch> {
    // Phase 1: Exact name matching
    const exactMatch = await this.dsRegistry.findByName(
      component.name,
      projectContext.designSystem
    );
    
    if (exactMatch && exactMatch.confidence > 0.9) {
      return exactMatch;
    }

    // Phase 2: Fuzzy name + style matching
    const fuzzyMatches = await this.dsRegistry.findSimilar(
      component.name,
      component.styles,
      { threshold: 0.7 }
    );

    // Phase 3: Semantic similarity using embeddings
    const semanticMatches = await this.vectorDB.findSimilar(
      this.componentToEmbedding(component),
      { limit: 5, threshold: 0.8 }
    );

    // Combine matches with weighted scoring
    const bestMatch = this.combinematches([
      ...fuzzyMatches,
      ...semanticMatches
    ]);

    return {
      matchedComponentId: bestMatch?.id || null,
      matchConfidence: bestMatch?.confidence || 0,
      suggestedMapping: bestMatch?.filePath || null,
      variations: bestMatch?.variations || [],
      source: bestMatch ? 'fuzzy' : 'none'
    };
  }

  private componentToEmbedding(component: NormalizedComponent): number[] {
    // Convert component to vector representation
    const features = [
      ...this.nameToVector(component.name),
      ...this.styleToVector(component.styles),
      ...this.layoutToVector(component.layout)
    ];
    return features;
  }
}
```

### Lightweight ML Inference Pipeline

```typescript
class ProductionInferenceEngine {
  private heuristicClassifier: HeuristicClassifier;
  private mlClassifier: LightweightMLClassifier;
  private llmAnnotator: BatchLLMAnnotator;

  async analyze(normalizedData: NormalizedComponent[]): Promise<SemanticAnalysis[]> {
    const results: SemanticAnalysis[] = [];

    for (const component of normalizedData) {
      // Phase 1: Fast heuristic classification
      const heuristicResult = await this.heuristicClassifier.classify(component);
      
      if (heuristicResult.confidence > 0.9) {
        // High confidence - use heuristic result
        results.push(this.buildSemanticAnalysis(component, heuristicResult));
        continue;
      }

      // Phase 2: Lightweight ML classification
      const mlResult = await this.mlClassifier.classify(component);
      
      if (mlResult.confidence > 0.8) {
        // Good ML confidence - use ML result
        results.push(this.buildSemanticAnalysis(component, mlResult));
        continue;
      }

      // Phase 3: Queue for LLM annotation (batch processed)
      await this.llmAnnotator.enqueue(component);
      // Return preliminary result for now
      results.push(this.buildSemanticAnalysis(component, mlResult, { preliminary: true }));
    }

    // Process LLM batch if any components queued
    await this.llmAnnotator.processBatch();

    return results;
  }
}
```

### Batch LLM Annotation System

```typescript
class BatchLLMAnnotator {
  private queue: ComponentBatch[] = [];
  private batchSize = 10;
  private maxTokensPerComponent = 200;

  async enqueue(component: NormalizedComponent): Promise<void> {
    this.queue.push({
      component,
      timestamp: Date.now()
    });

    // Auto-process when batch is full
    if (this.queue.length >= this.batchSize) {
      await this.processBatch();
    }
  }

  async processBatch(): Promise<void> {
    if (this.queue.length === 0) return;

    const batch = this.queue.splice(0, this.batchSize);
    
    try {
      // Build compact batch prompt
      const prompt = this.buildBatchPrompt(batch.map(b => b.component));
      
      // Single LLM call for entire batch
      const response = await this.llmClient.annotate({
        prompt,
        maxTokens: this.maxTokensPerComponent * batch.length,
        temperature: 0.1 // Low temperature for consistent classification
      });

      // Parse and distribute results
      const results = this.parseBatchResponse(response);
      await this.distributeBatchResults(batch, results);
      
    } catch (error) {
      console.error('Batch LLM annotation failed:', error);
      // Fallback to ML-only results
      await this.fallbackToML(batch);
    }
  }

  private buildBatchPrompt(components: NormalizedComponent[]): string {
    return `
TASK: Classify design components and infer intent. Return JSON only.

COMPONENTS:
${components.map((comp, i) => `
${i + 1}. Name: "${comp.name}"
   Type: ${comp.type}
   Text: "${comp.content?.text || 'none'}"
   Layout: ${comp.layout.direction}
   Size: ${comp.bounds.w}x${comp.bounds.h}
`).join('')}

RETURN: Array of objects with:
- semanticType: "button|input|card|nav|content|banner|modal|list"
- intent: { purpose: "conversion|navigation|info|interaction", priority: "high|medium|low" }
- userAction: "click|input|submit|navigate|view|none"

JSON:
`;
  }
}
```

## Phase 5: Compression & Output Generation

### Intelligent Compression Strategy

```typescript
class IntelligentCompressor {
  async compressForLLM(enrichedData: SemanticAnalysis[]): Promise<CompressedDesignSpec> {
    // Phase 1: Remove redundant data
    const deduplicated = this.deduplicateComponents(enrichedData);
    
    // Phase 2: Summarize repetitive patterns
    const summarized = this.summarizeRepetition(deduplicated);
    
    // Phase 3: Compress visual assets
    const compressed = await this.compressAssets(summarized);
    
    // Phase 4: Validate token budget
    const final = this.enforceTokenBudget(compressed, { maxTokens: 6000 });
    
    return final;
  }

  private deduplicateComponents(data: SemanticAnalysis[]): SemanticAnalysis[] {
    const seen = new Map<string, SemanticAnalysis>();
    
    return data.filter(component => {
      const key = this.generateComponentKey(component);
      if (seen.has(key)) {
        // Merge similar components
        const existing = seen.get(key)!;
        existing.instances = (existing.instances || 1) + 1;
        return false;
      }
      seen.set(key, component);
      return true;
    });
  }

  private summarizeRepetition(data: SemanticAnalysis[]): SemanticAnalysis[] {
    return data.map(component => {
      // If component appears multiple times, create summary
      if (component.instances && component.instances > 3) {
        return {
          ...component,
          contentSummary: {
            ...component.contentSummary,
            text: this.summarizeText(component.contentSummary.text),
            note: `Repeated ${component.instances} times with variations`
          }
        };
      }
      return component;
    });
  }

  private async compressAssets(data: SemanticAnalysis[]): Promise<SemanticAnalysis[]> {
    // Limit to 1 low-res screenshot per major component
    const withLimitedAssets = data.map(component => ({
      ...component,
      assets: component.assets?.slice(0, 1) || [], // Max 1 asset
      snapshots: component.snapshots?.filter(s => s.type === 'low-res').slice(0, 1) || []
    }));

    return withLimitedAssets;
  }

  private enforceTokenBudget(data: SemanticAnalysis[], budget: { maxTokens: number }): CompressedDesignSpec {
    const estimated = this.estimateTokens(data);
    
    if (estimated <= budget.maxTokens) {
      return { data, compressionRatio: 1.0, estimatedTokens: estimated };
    }

    // Progressive compression
    let compressed = data;
    let ratio = 1.0;

    // Step 1: Remove detailed descriptions
    if (this.estimateTokens(compressed) > budget.maxTokens) {
      compressed = this.removeDetailedDescriptions(compressed);
      ratio = 0.8;
    }

    // Step 2: Truncate content summaries
    if (this.estimateTokens(compressed) > budget.maxTokens) {
      compressed = this.truncateContentSummaries(compressed);
      ratio = 0.6;
    }

    // Step 3: Remove non-essential components
    if (this.estimateTokens(compressed) > budget.maxTokens) {
      compressed = this.filterEssentialComponents(compressed);
      ratio = 0.4;
    }

    return {
      data: compressed,
      compressionRatio: ratio,
      estimatedTokens: this.estimateTokens(compressed),
      warning: ratio < 0.7 ? 'Significant compression applied - some data lost' : undefined
    };
  }
}
```

### Production Pipeline Orchestration

```typescript
class ProductionDesignIntelligencePipeline {
  async extractFrame(
    fileKey: string, 
    nodeId: string, 
    opts: ExtractionOptions
  ): Promise<DesignSpec> {
    
    const startTime = Date.now();
    
    try {
      // Phase 1: Collection with rate limiting
      console.log(`üîç Collecting raw data for ${nodeId}...`);
      const rawData = await this.extractor.extractRawData(fileKey, nodeId, opts);
      
      // Phase 2: Normalization with error handling
      console.log(`‚öôÔ∏è Normalizing ${rawData.nodeTree.children?.length || 0} nodes...`);
      const normalizedData = await this.normalizer.normalize(rawData);
      
      // Phase 3: Design System matching
      console.log(`üé® Matching to design system...`);
      const dsMatches = await this.dsReferencer.matchComponents(normalizedData, opts.projectContext);
      
      // Phase 4: Heuristic + ML inference
      console.log(`üß† Running semantic inference...`);
      const semanticData = await this.inferenceEngine.analyze(normalizedData);
      
      // Phase 5: LLM enrichment (batch)
      console.log(`‚ú® LLM enrichment batch processing...`);
      const enrichedData = await this.enrichmentEngine.enrich(semanticData, rawData);
      
      // Phase 6: Compression for LLM consumption
      console.log(`üì¶ Compressing for LLM consumption...`);
      const compressed = await this.compressor.compressForLLM(enrichedData);
      
      // Phase 7: Generate final design spec
      console.log(`üìã Generating design spec...`);
      const designSpec = await this.assembleDesignSpec({
        rawData,
        normalizedData,
        dsMatches,
        semanticData: compressed.data,
        metadata: {
          processingTimeMs: Date.now() - startTime,
          compressionRatio: compressed.compressionRatio,
          estimatedTokens: compressed.estimatedTokens
        }
      });
      
      // Phase 8: Save and cache
      await this.saveSpec(designSpec);
      
      console.log(`‚úÖ Extraction complete: ${designSpec.extractionStats.nodeCount} nodes, ${designSpec.components.length} components`);
      
      return designSpec;
      
    } catch (error) {
      console.error(`‚ùå Extraction failed for ${nodeId}:`, error);
      
      // Generate minimal fallback spec
      return this.generateFallbackSpec(fileKey, nodeId, error);
    }
  }

  private async generateFallbackSpec(
    fileKey: string, 
    nodeId: string, 
    error: any
  ): Promise<DesignSpec> {
    return {
      meta: {
        fileKey,
        frameId: nodeId,
        frameName: 'Unknown Frame',
        extractedAt: new Date().toISOString(),
        extractorVersion: this.version,
        sourceUrl: `https://figma.com/file/${fileKey}`,
        confidence: 0.1
      },
      projectContext: {
        projectId: 'unknown',
        projectName: 'Unknown Project',
        pageType: 'app',
        targetDevices: ['desktop'],
        team: 'unknown',
        techStack: ['React']
      },
      tokens: {},
      components: [],
      relationships: { hierarchy: [] },
      interactionGraph: { nodes: [], edges: [] },
      assets: [],
      snapshots: [],
      inferredIntent: {
        primaryGoal: 'information',
        priority: 'low',
        a11yRiskScore: 0.5
      },
      extractionStats: {
        nodeCount: 0,
        componentInstances: 0,
        tokensUsed: 0,
        payloadSizeBytes: 0,
        processingTimeMs: 0,
        confidenceDistribution: { high: 0, medium: 0, low: 1 }
      },
      validation: {
        schemaVersion: '1.0',
        isValid: false,
        warnings: [`Extraction failed: ${error.message}`],
        suggestions: ['Try extracting a smaller frame or check Figma permissions']
      }
    };
  }
}
```

### Pseudocode Implementation

```javascript
// High-level production extraction flow
async function extractFrame(fileKey, nodeId, opts) {
  // 1. Select / Partition
  const frames = opts.autoDetect 
    ? await detectDevReadyFrames(fileKey)
    : await findTaggedFrames(fileKey, ['#for-dev', '#dev-ready']);
  
  const partitions = await partitionLargeFrames(frames);
  
  // 2. Raw extraction with rate limiting
  const meta = await figma.get_metadata({fileKey, nodeId, useCache: true});
  const nodes = normalize(meta);
  const tokens = extractTokens(nodes);
  const snapshots = await figma.get_screenshot({fileKey, nodeId, resolution: 'low'});
  
  // 3. Design System cross-reference
  const dsMatches = await matchDesignSystem(nodes, opts.projectContext);
  
  // 4. Heuristic + ML inference
  const heuristics = runHeuristics(nodes);
  const mlInference = await runLightweightML(nodes);
  
  // 5. LLM annotation (batch)
  const annotated = await llmAnnotate(nodes, {
    projectContext: opts.projectContext,
    techStack: opts.techStack,
    batchSize: 10
  });
  
  // 6. Compress for LLM
  const compressed = compressForLLM(annotated, {maxTokens: 6000});
  
  // 7. Build and save spec
  const spec = buildDesignSpec({
    compressed,
    tokens,
    dsMatches,
    snapshots,
    metadata: {processingTime, confidence}
  });
  
  await saveSpec(spec);
  return spec;
}
```

This production pipeline transforms raw Figma rectangles into intelligent, compressed, LLM-ready design specifications ‚Äî ready for real-world deployment with proper error handling, rate limiting, and quality assurance.

## üîÑ Pipeline Orchestration

### Main Processing Flow

```typescript
class DesignIntelligencePipeline {
  async process(figmaFileId: string, nodeId: string): Promise<DesignIntelligence> {
    // Phase 1: Collection
    const rawData = await this.extractor.extractRawData(figmaFileId, nodeId);
    
    // Phase 2: Normalization
    const normalizedData = await this.normalizer.normalize(rawData);
    
    // Phase 3: Inference
    const semanticData = await this.inferenceEngine.analyze(normalizedData);
    
    // Phase 4: Enrichment
    const enrichedData = await this.enrichmentEngine.enrich(semanticData, rawData);
    
    // Phase 5: Code Hints
    const codeHints = await this.codeHintGenerator.generate(enrichedData);
    
    return this.assembleDesignIntelligence(enrichedData, codeHints);
  }

  private async assembleDesignIntelligence(
    semanticData: SemanticAnalysis,
    codeHints: CodeHints
  ): Promise<DesignIntelligence> {
    return {
      metadata: {
        version: '1.0',
        figmaFileId: semanticData.source.fileId,
        extractedAt: new Date().toISOString(),
        confidence: this.calculateOverallConfidence(semanticData),
        source: 'figma_mcp'
      },
      component: semanticData.component,
      intent: semanticData.intent,
      ui: semanticData.ui,
      designTokens: semanticData.tokens,
      content: semanticData.content,
      behaviors: semanticData.behaviors,
      relationships: semanticData.relationships,
      context: semanticData.context,
      accessibility: semanticData.accessibility,
      codeHints
    };
  }
}
```

### Error Handling & Fallbacks

```typescript
class RobustPipeline {
  async processWithFallbacks(figmaFileId: string, nodeId: string): Promise<DesignIntelligence> {
    try {
      return await this.pipeline.process(figmaFileId, nodeId);
    } catch (error) {
      console.warn('Full pipeline failed, attempting fallback extraction:', error);
      
      try {
        // Fallback to basic extraction
        return await this.basicExtractor.extract(figmaFileId, nodeId);
      } catch (fallbackError) {
        console.error('Fallback extraction failed:', fallbackError);
        
        // Return minimal intelligence with error context
        return this.generateMinimalIntelligence(figmaFileId, nodeId, error);
      }
    }
  }
}
```

This pipeline transforms raw Figma rectangles into rich, semantic intelligence that AI systems can actually reason about ‚Äî turning design files into the structured context that powers truly intelligent code generation.